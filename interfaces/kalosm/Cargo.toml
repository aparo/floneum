[package]
name = "kalosm"
version = "0.2.2"
edition = "2021"
description = "A simple interface for pretrained AI models "
license = "MIT/Apache-2.0"
repository = "https://github.com/floneum/floneum"
authors = ["Evan Almloff"]
keywords = ["llm", "llama", "whisper", "ocr", "nlp"]

[dependencies]
kalosm-language = { default-features = false, workspace = true, optional = true }
kalosm-sound = { workspace = true, optional = true }
kalosm-vision = { workspace = true, optional = true }
kalosm-streams.workspace = true
llm-samplers.workspace = true
tokio = { version = "1.32.0", features = ["full", "macros", "rt-multi-thread"] }
futures-util = "0.3.28"
anyhow = "1.0.75"
rand = "0.8.5"
image = "0.24.7"
tracing = "0.1.40"
async-trait = "0.1.74"
hdrhistogram = "7.5.4"
num-traits = "0.2.17"
once_cell = "1.19.0"
comfy-table = "7.1.0"
serde = { version = "1.0.163", features = ["derive"] }
surrealdb = { version = "1.1.1", features = ["kv-rocksdb"], optional = true }
kalosm-common = { version = "0.1.0", path = "../kalosm-common" }

[dev-dependencies]
axum = "0.7.2"
tracing-subscriber = "0.2"
tokenizers = "0.15.0"
candle-core = { workspace = true }
candle-nn = { workspace = true }
candle-datasets = { workspace = true }
candle-transformers = { workspace = true }
scraper = "0.18.1"
ego-tree = "0.6.2"
kalosm-llama = { workspace = true }

[features]
default = ["language", "sound", "vision", "surrealdb"]
llamacpp = ["kalosm-language/llamacpp"]
metal = ["kalosm-language/metal", "kalosm-vision/metal", "kalosm-sound/metal"]
cublas = ["kalosm-language/cublas"]
mkl = ["kalosm-language/mkl", "kalosm-vision/mkl", "kalosm-sound/mkl"]
language = ["kalosm-language"]
sound = ["kalosm-sound"]
vision = ["kalosm-vision"]
surrealdb = ["dep:surrealdb"]
